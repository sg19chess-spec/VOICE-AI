# Gradual Scaling Guide
## Tamil Nadu MLA Voice Complaint System

Scale from 1 MLA to 234 MLAs gradually, paying only for what you use.

---

## ðŸŽ¯ Scaling Phases

### Phase 1: Pilot (1-10 MLAs)
**Timeline:** Weeks 1-4
**Goal:** Test system, get feedback, refine workflow

#### Option A: Local Testing (FREE)
```bash
cd voice-agent
./test-local.sh
python src/agent.py console
```
**Cost:** â‚¹0/month

#### Option B: LiveKit Cloud Free Tier
```bash
lk agent create
```
**Cost:** â‚¹0/month (within 1,000 min)
**Limit:** ~16 hours of calls/month

#### Option C: RunPod CPU Instance
```bash
./deploy-runpod.sh --instance-type cpu
```
**Cost:** â‚¹2,500/month (24/7)
**Or:** â‚¹750/month (office hours only)

**Recommended:** Start with Option B (LiveKit Cloud Free)

---

### Phase 2: Regional Rollout (10-50 MLAs)
**Timeline:** Month 2-3
**Goal:** Expand to 2-3 districts

#### Option A: LiveKit Cloud (Ship Plan)
- Handles 20 concurrent sessions
- $50/month base + $0.01/min
**Cost:** â‚¹8,000-12,000/month

#### Option B: RunPod Small GPU
- RTX 3070: $0.30/hour
- Handles 50 concurrent sessions
**Cost:**
- 24/7: â‚¹7,500/month
- Office hours (12h): â‚¹3,750/month
- Business days (264h): â‚¹2,640/month

**Recommended:** Option B with office hours

---

### Phase 3: State-wide (50-150 MLAs)
**Timeline:** Month 4-6

#### RunPod Medium GPU
- RTX 4070: $0.45/hour
- Handles 120 concurrent sessions

**Cost:**
- 24/7: â‚¹11,250/month
- Office hours: â‚¹5,625/month
- Business days: â‚¹3,960/month

**Recommended:** Business days mode

---

### Phase 4: Full Deployment (150-234 MLAs)
**Timeline:** Month 7+

#### RunPod High-End GPU
- RTX 4090: $0.69/hour
- Handles 240+ concurrent sessions

**Cost:**
- 24/7: â‚¹17,250/month
- Office hours: â‚¹8,625/month
- Business days: â‚¹6,072/month

**Recommended:** Office hours mode

---

## ðŸ’° Cost Comparison by Phase

| Phase | MLAs | Best Option | 24/7 Cost | Office Hours | Business Days |
|-------|------|-------------|-----------|--------------|---------------|
| Pilot | 1-10 | LiveKit Free | â‚¹0 | â‚¹0 | â‚¹0 |
| Regional | 10-50 | RunPod 3070 | â‚¹7,500 | â‚¹3,750 | â‚¹2,640 |
| State-wide | 50-150 | RunPod 4070 | â‚¹11,250 | â‚¹5,625 | â‚¹3,960 |
| Full | 150-234 | RunPod 4090 | â‚¹17,250 | â‚¹8,625 | â‚¹6,072 |

---

## ðŸ¤– Auto-Scaling (Recommended)

Save **70-80%** by automatically scaling RunPod instances based on actual demand!

### How It Works

The included auto-scaler (`autoscaler.py`) automatically:
1. **Monitors LiveKit** for active sessions every 5 minutes
2. **Creates instances** when calls come in
3. **Scales up** when load increases (30â†’80â†’150â†’240 sessions)
4. **Scales down** when load decreases
5. **Stops instances** after 30 minutes of idle time

### Automatic Setup

The auto-scaler is installed during deployment:

```bash
sudo ./deploy-runpod.sh
# Answer "y" when asked about auto-scaling
```

### Manual Setup

If you need to set it up later:

```bash
# Install dependencies
pip3 install -r autoscaler-requirements.txt

# Copy systemd service
sudo cp autoscaler.service /etc/systemd/system/

# Enable and start
sudo systemctl daemon-reload
sudo systemctl enable autoscaler.service
sudo systemctl start autoscaler.service

# View logs
sudo journalctl -u autoscaler -f
```

### Scaling Rules

The auto-scaler follows these rules:

| Sessions | GPU Type | Cost/Hour | Monthly (24/7) | Monthly (Business Days) |
|----------|----------|-----------|----------------|------------------------|
| 1-30 | RTX 3070 | $0.30 | â‚¹7,500 | â‚¹2,640 |
| 31-80 | RTX 4070 | $0.45 | â‚¹11,250 | â‚¹3,960 |
| 81-150 | RTX 4080 | $0.60 | â‚¹15,000 | â‚¹5,280 |
| 151-240 | RTX 4090 | $0.69 | â‚¹17,250 | â‚¹6,072 |
| 0 (idle 30min) | STOPPED | $0 | â‚¹0 | â‚¹0 |

### Real Cost Examples

**Scenario 1: Pilot Phase (5 MLAs)**
- Average 2-3 concurrent sessions
- Runs only when calls come in
- Idle stop after 30 minutes
- **Actual cost: â‚¹500-800/month** (vs â‚¹7,500 without auto-scaling)

**Scenario 2: Regional (30 MLAs)**
- Average 10-15 concurrent sessions during office hours
- Stops at night and weekends
- **Actual cost: â‚¹1,500-2,000/month** (vs â‚¹7,500 without auto-scaling)

**Scenario 3: Full Deployment (234 MLAs)**
- Average 80-100 concurrent sessions during office hours
- Peak 150+ sessions during high-traffic times
- Stops at night, scales down on weekends
- **Actual cost: â‚¹6,000-8,000/month** (vs â‚¹42,000 without auto-scaling)

### Cost Savings Summary

| Deployment | Without Auto-Scaling | With Auto-Scaling | Savings |
|------------|---------------------|-------------------|---------|
| Pilot (5 MLAs) | â‚¹7,500/month | â‚¹600/month | **92%** |
| Regional (30 MLAs) | â‚¹7,500/month | â‚¹1,800/month | **76%** |
| Full (234 MLAs) | â‚¹42,000/month | â‚¹7,000/month | **83%** |

**Total 7-month cost with auto-scaling:** ~â‚¹15,000
**vs without auto-scaling:** ~â‚¹1.2 lakh
**Total Savings: â‚¹1.05 lakh!**

---

## ðŸ“Š Recommended Path (With Auto-Scaling)

### Month 1: FREE
- Test locally: 1-2 MLAs
- Use LiveKit Cloud free tier
- Refine Tamil conversations
- **Cost: â‚¹0**

### Month 2: â‚¹600
- Deploy 5-10 MLAs
- RunPod with auto-scaling
- RTX 3070 (only when calls come in)
- Collect feedback
- **Cost: ~â‚¹600/month** (vs â‚¹2,640 without auto-scaling)

### Month 3-4: â‚¹1,800
- Expand to 20-30 MLAs
- Auto-scales between RTX 3070/4070
- Stops at night and weekends
- **Cost: ~â‚¹1,800/month** (vs â‚¹3,960 without auto-scaling)

### Month 5-6: â‚¹4,000
- Expand to 80-120 MLAs
- Auto-scales between RTX 4070/4080
- Smart scaling during office hours
- **Cost: ~â‚¹4,000/month** (vs â‚¹6,072 without auto-scaling)

### Month 7+: â‚¹7,000
- Full 234 MLAs
- Auto-scales to RTX 4090 during peak times
- Scales down during off-peak
- Stops when idle
- **Cost: ~â‚¹7,000/month** (vs â‚¹42,000 without auto-scaling)

**Total Spent (7 months):** ~â‚¹15,000
**vs without auto-scaling:** ~â‚¹1.2 lakh
**vs buying full infrastructure upfront:** â‚¹2.9 lakh

**Total Savings: â‚¹2.75 lakh!** (95% savings)

---

## ðŸŽ¯ Action Plan

### This Week
```bash
# Test on your PC
cd C:\Users\sg13c\Documents\VOICE-AI\voice-agent
git pull
./test-local.sh
python src/agent.py console
```

### Next Week
```bash
# Deploy to LiveKit Cloud (free tier)
lk agent create --secrets-file secrets.txt
# Test with 2-3 MLAs
```

### Month 2
```bash
# Get RunPod account
# Deploy small instance
# Onboard 5-10 MLAs
```

### Month 3+
```bash
# Scale gradually as you add MLAs
# Upgrade instance when needed
```

---

## ðŸ“ž Support

Questions? Contact:
- GitHub Issues
- Email: support@tnmla.in

---

**Start small, scale smart!** ðŸš€
